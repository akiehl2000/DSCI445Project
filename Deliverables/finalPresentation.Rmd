---
title: "Final Presentation"
author: "Zach Brazil, Richard Charles, and Adam Kiehl"
date: "12/8/21"
output: 
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introduction

# Data

# Passing Analysis pt. 1

Models that were used:
  - Multiple Linear Regression (MLR)
  - LASSO
  - Principal Component Analysis/Regression
  - Tree
  - Bagging

Predictors: `Cmp`, `PassAtt`, `Sk`, `YdsLost`, `PassLng`, `Rate`, `FirstDPass`, `FirstDPassPer`, `CAY`, `YACPerCmp`, `PassDrops`, `BadThrow`, `BadPer`

Dropped `PassYAC` (multicollinearity)

# Passing Analysis pt. 2

```{r}
par(mfrow = c(2,2))

#Plot 1: Scree Plot
readRDS('../Plots/pcplot.rds')

#Plot 2: PassYds as Response
readRDS('../Plots/passydstree.rds')


# Plot 3: PassInt as Response
tree_model = tree(PassInt ~ . - PassYds - PassTD - FL, train_data)
cv_tree = cv.tree(tree_model)
tree_model = prune.tree(tree_model, best = '12')
plot(tree_model)
text(tree_model)

# Plot 4: PassTD as Response
tree_model = tree(PassTD ~ . - PassYds - PassInt - FL, train_data)
cv_tree = cv.tree(tree_model)
plot(tree_model)
text(tree_model)

# Plot 5: FL as Response
tree_model = tree(FL ~ . - PassYds - PassInt - PassTD, train_data)
cv_tree = cv.tree(tree_model)
plot(tree_model)
text(tree_model)
```

# Passing Analysis pt. 3

```{r}
readRDS('../Tables/master.rds')
```

# Receiving Analysis pt. 1

Predictors: Tgt, RecLng, Fmb, FirstDRec, RecYBC, YBCPerR, RecYAC, YACPerR, ADOT, RecBrkTkl, RecPerBr, RecDrop, DropPerRec, RecInt, Rat
- Goal of simplicity and predictive accuracy
- Correlation matrix and VIF scores to identify multicollinearity (`FirstDRec`, `RecYBC`, `YBCPerR`, `YACPerR`, `DropPerRec`)
- `RecYAC` dropped
- Dimension reduction techniques
  - Best Subset -> 3-5 predictors used with `Tgt` and `Rat` appearing most frequently
  - LASSO -> 5-10 predictors used but didn't perform better than best subset 
  - PC regression -> 7-8 principal components used (sharp dropoff afterwards); excellent performance for `RecYds`
  - Pruned trees -> 2 terminal nodes used for `RecTD` and 6-7 otherwise. `Tgt` and `Rat`
  - Bagging and Random Forest -> 1-5 important variables with excellent predictive performance
- Rec: Random forest model chosen with `Tgt`, `FirstDRec`, `RecYAC`, `RecYBC`, `Rat` (sandwich)
PLOT OF VARIABLE IMPROTANCE
- RecYds: Bagged tree model chosen with `RecYBC` (primarily), `FirstDRec`, `RecLng`, `YACPerR`
PLOT OF VARIABLE IMPORTANCE
- RecTD: Bagged tree model chose `Rat` as the only important variable so a regular tree with just `Rat` performed just as well
PLOT OF TREE

# Receiving Analysis pt. 2

# Receiving Analysis pt. 3

# Rushing Analysis pt. 1

# Rushing Analysis pt. 2

# Rushing Analysis pt. 3

# Fumbles Analysis

# Results

# Validation

# Future Efforts

- Refit Random Forest models with better subset of predictors
- Injuries
- Strength of opponent
- Assuming a Poisson distribution for Rec, TD, Int, FL
